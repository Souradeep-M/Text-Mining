---
title: "F.R.I.E.N.D.S"
author: "Souradeep Mondal"
date: "03/08/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
F.R.I.E.N.D.S Text Mining & Data Visualization


#### PACKAGES & DATA

## PACKAGES
```{r}
library(tidyverse)
library(tidytext)
library(topicmodels)
library(DT)
library(png)
library(grid)
```


## Data
```{r}
# Friends Logo
img <- readPNG("Friends_logo.png")
img <- rasterGrob(img, interpolate=TRUE)

afinn <- read.csv("afinn.csv", stringsAsFactors = FALSE)[-1]
nrc <- read.csv("nrc.csv", stringsAsFactors = FALSE)[-1]
bing <- read.csv("bing.csv", stringsAsFactors = FALSE)[-1]
loughran <- read.csv("loughran.csv", stringsAsFactors = FALSE)[-1]


# Text 
df <- read.csv("friends_quotes.csv", stringsAsFactors = FALSE, encoding = "UTF-8")
df %>% as_tibble()
df %>% group_by(season) %>% summarise(episode_number = max(episode_number))
```


#### TIDY TEXT
```{r}
tidy_text <- df %>%
  # N-Gram
  unnest_tokens(word, quote) %>% 
  # Remove Stop Words
  anti_join(stop_words) %>%
  # Remove Character Names
  filter(!word %in% tolower(author))

# I removed few words
tidy_text <- tidy_text %>% 
  filter(!word %in% c("uhm", "it’s", "ll", "im", "don’t", "i’m", "that’s", "ve", "that’s","you’re",
                      "woah", "didn", "what're", "alright", "she’s", "we’re", "dont", "c'mere", "wouldn",
                      "isn","pbs", "can’t", "je", "youre", "doesn", "007", "haven", "whoah", "whaddya", 
                      "somethin", "yah", "uch", "i’ll","there’s", "won’t", "didn’t", "you’ll", "allright",
                      "yeah", "hey", "uh", "gonna", "umm","um", "y'know", "ah", "ohh", "wanna", "ya", "huh", "wow",
                      "whoa", "ooh")) %>% 
  mutate(word = str_remove_all(word, "'s")) 

tidy_text %>% as_tibble()
```


#### SENTIMENT LEXICONS
```{r}
datatable(bing)
datatable(nrc)
datatable(afinn)
datatable(loughran)
```


#### SENTIMENT ANALYSIS
```{r}
tidy_bing <- tidy_text %>% inner_join(bing)
tidy_nrc <- tidy_text %>% inner_join(nrc)
tidy_afinn <- tidy_text %>% inner_join(afinn)

tidy_nrc %>% 
  filter(author %in% c("Ross", "Monica", "Rachel", "Joey", "Chandler", "Phoebe")) %>% 
  ggplot(aes(sentiment, fill = author))+
  geom_bar(show.legend = FALSE)+
  facet_wrap(author~.)+
  theme_dark()+
  theme(
    strip.text = element_text(face = "bold"),
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold")
  )+
  labs(fill = NULL, x = NULL, y = "Sentiment Frequency", title = "Sentiments of each characters by using nrc lexicon")+
  scale_fill_manual(values = c("#EA181E", "#00B4E8", "#FABE0F","#EA181E", "#00B4E8", "#FABE0F"))+
  annotation_custom(img,ymax = 4000, ymin = 2000, xmin = 1, xmax = 5)
```

```{r}
tidy_bing %>% 
  filter(author %in% c("Ross", "Monica", "Rachel", "Joey", "Chandler", "Phoebe")) %>% 
  group_by(season, author) %>% 
  count(sentiment) %>%
  ungroup() %>%
  ggplot(aes(season, n, fill = sentiment)) +
  geom_col(position = "fill") +
  geom_text(aes(label = n), position = position_fill(0.5), color = "white")+
  coord_flip()+
  facet_wrap(author~.)+
  theme_dark()+
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold")
    )+
  scale_fill_manual(values = c("#EA181E", "#00B4E8"))+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))+
  labs(y = NULL,  x = "Season", fill = NULL, title = "Negative-Positive Ratio in all seasons by using bing lexicon")
```


```{r}
df %>% 
  group_by(season) %>% 
  mutate(seq = row_number()) %>% 
  ungroup() %>% 
  unnest_tokens(word, quote) %>% 
  anti_join(stop_words) %>% 
  filter(!word %in% tolower(author)) %>% 
  inner_join(bing) %>% 
  count(season, index = seq %/% 50, sentiment) %>% 
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  ggplot(aes(index, sentiment, fill = factor(season))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(paste0("Season ",season)~., ncol = 2, scales = "free_x")+
  theme_dark()+
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold"))+
  labs(x = "Index", y = "Sentiment", title = "Negative-Positive Distribution in all seasons by using afinn lexicon")
```

```{r}
all <- tidy_afinn %>% 
  mutate(Episode = factor(paste0("S",season,"-","E",episode_number))) %>% 
  group_by(Episode) %>% 
  summarise(total = sum(value), .groups = 'drop') %>% 
  ungroup %>% 
  mutate(Neg = if_else(total < 0, TRUE, FALSE))


ggplot()+
  geom_path(all, mapping = aes(Episode, total, group = 1), color = "#BA0E00")+
  geom_hline(mapping = aes(yintercept = 0), color = "#024D38")+
  theme_classic()+
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5, color = "#EA181E", size = 20, face = "bold"))+
  geom_text((all %>% filter(Neg == TRUE)), mapping = aes(Episode, total-15, label = Episode), angle = 90, size = 3)+
  annotation_custom(img, ymin = 170, ymax = 220, xmin = 10, xmax = 60)+
  labs(title = "Total Sentiment Score each Episode with Afinn Lexicon", 
       y = "Total Sentiment Score")
```

```{r}
tidy_afinn %>% 
  filter(author %in% c("Ross", "Monica", "Rachel", "Joey", "Chandler", "Phoebe")) %>% 
  group_by(season, author) %>% 
  summarise(total = sum(value), .groups = 'drop') %>% 
  ungroup() %>% 
  mutate(Neg = if_else(total < 0, TRUE, FALSE)) %>% 
  ggplot()+
  geom_path(aes(season, total, color = author), size = 1.2)+
  theme_minimal()+
  theme(legend.position = "bottom")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))+
  scale_color_manual(values = c("#EA181E", "#00B4E8", "#FABE0F", "seagreen2", "orchid", "royalblue"))+
  labs(x = "Season", color = NULL, y = "Total Sentiment Score")+
  annotation_custom(img, ymin = 350, ymax = 400, xmin = 1, xmax = 4)
```

#### TF-IDF
```{r}
tidy_text %>% 
  group_by(season) %>% 
  count(word) %>% 
  ungroup() %>% 
  bind_tf_idf(word, season, n) %>% 
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%  
  group_by(season) %>% 
  count(word) %>% 
  ungroup() %>% 
  bind_tf_idf(word, season, n) %>% 
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(season) %>% 
  top_n(10) %>% 
  ungroup() %>% 
  ggplot(aes(word, tf_idf, fill = factor(season))) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "TF-IDF", "TF-IDF & Seasons") +
  facet_wrap(~season, ncol = 3, scales = "free") +
  coord_flip()+
  scale_fill_ordinal()+
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold"))

```
#### TOPIC MODELLING
```{r}
# Document-Term Matrix
dtm <- tidy_text %>% 
  select(season, word) %>% 
  group_by(season, word) %>% 
  count() %>% 
  cast_dtm(season, word, n)

dtm
```


```{r}
# set a seed so that the output of the model is predictable
lda <- LDA(dtm, k = 10, control = list(seed = 1234))
lda
```

#### Word-Topic Probabilities
```{r}
topics <- tidy(lda, matrix = "beta")

top_terms <- topics %>%group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)


top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()+
  labs(title = "Word-Topic Probabilities")+
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold"))
```
#### Document-Topic Probabilities
```{r}
documents <- tidy(lda, matrix = "gamma")

documents %>% 
  ggplot(aes(document, gamma, fill = factor(topic)))+
  geom_col(position = "fill")+
  labs(x = "Season", fill = "Topic", y = "Gamma", title = "Document-Topic Probabilities")+
  scale_fill_ordinal()+
  theme(
    legend.position = "top",
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold")
  )
```

